# æ·»åŠ è‡ªå®šä¹‰Hugging Faceæ¨¡å‹æŒ‡å—

æœ¬æŒ‡å—å°†è¯¦ç»†è¯´æ˜å¦‚ä½•åœ¨MER-Factoryé¡¹ç›®ä¸­æ·»åŠ æ–°çš„Hugging Faceå•æ¨¡æ€æ¨¡å‹æ”¯æŒã€‚

## ğŸ“‹ æ¦‚è¿°

MER-Factoryæ”¯æŒå¤šç§ç±»å‹çš„AIæ¨¡å‹ï¼ŒåŒ…æ‹¬ï¼š
- **å¤šæ¨¡æ€æ¨¡å‹**ï¼šæ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ï¼ˆå¦‚Qwen2.5-Omniï¼‰
- **å•æ¨¡æ€æ¨¡å‹**ï¼šä¸“é—¨å¤„ç†ç‰¹å®šç±»å‹çš„æ•°æ®ï¼ˆå¦‚Qwen2-Audioï¼‰
- **æ–‡æœ¬æ¨¡å‹**ï¼šçº¯æ–‡æœ¬ç”Ÿæˆå’Œåˆ†æï¼ˆå¦‚LLaMAã€Mistralï¼‰

## ğŸ› ï¸ å®ç°æ­¥éª¤

### æ­¥éª¤1ï¼šåˆ›å»ºæ¨¡å‹ç±»

1. **å¤åˆ¶æ¨¡æ¿æ–‡ä»¶**ï¼š
   ```bash
   cp mer_factory/models/hf_models/custom_text_model.py mer_factory/models/hf_models/your_model.py
   ```

2. **ä¿®æ”¹ç±»åå’Œæ¨¡å‹ID**ï¼š
   ```python
   class YourModelName:  # ä¿®æ”¹ç±»å
       def __init__(self, model_id: str, verbose: bool = True):
           # ä¿®æ”¹ä¸ºä½ çš„å®é™…æ¨¡å‹ID
           # ä¾‹å¦‚: "your-org/your-model-name"
   ```

3. **æ ¹æ®æ¨¡å‹ç±»å‹è°ƒæ•´å®ç°**ï¼š
   - **æ–‡æœ¬æ¨¡å‹**ï¼šä½¿ç”¨ `AutoModelForCausalLM` å’Œ `AutoTokenizer`
   - **å›¾åƒæ¨¡å‹**ï¼šä½¿ç”¨ç›¸åº”çš„è§†è§‰æ¨¡å‹ç±»
   - **éŸ³é¢‘æ¨¡å‹**ï¼šä½¿ç”¨éŸ³é¢‘å¤„ç†ç›¸å…³çš„æ¨¡å‹ç±»

### æ­¥éª¤2ï¼šæ³¨å†Œæ¨¡å‹

åœ¨ `mer_factory/models/hf_models/__init__.py` ä¸­æ·»åŠ ä½ çš„æ¨¡å‹ï¼š

```python
HUGGINGFACE_MODEL_REGISTRY = {
    # ... ç°æœ‰æ¨¡å‹ ...
    "your-org/your-model-name": (".your_model", "YourModelName"),
}
```

### æ­¥éª¤3ï¼šå®ç°å¿…éœ€æ–¹æ³•

æ¯ä¸ªæ¨¡å‹ç±»å¿…é¡»å®ç°ä»¥ä¸‹æ ‡å‡†æ¥å£ï¼š

```python
def describe_facial_expression(self, prompt: str) -> str:
    """åˆ†æé¢éƒ¨è¡¨æƒ…"""
    pass

def describe_image(self, image_path: Path, prompt: str) -> str:
    """åˆ†æå›¾åƒï¼ˆå¦‚æœä¸æ”¯æŒåˆ™è¿”å›æç¤ºä¿¡æ¯ï¼‰"""
    pass

def analyze_audio(self, audio_path: Path, prompt: str) -> str:
    """åˆ†æéŸ³é¢‘ï¼ˆå¦‚æœä¸æ”¯æŒåˆ™è¿”å›æç¤ºä¿¡æ¯ï¼‰"""
    pass

def describe_video(self, video_path: Path, prompt: str) -> str:
    """åˆ†æè§†é¢‘ï¼ˆå¦‚æœä¸æ”¯æŒåˆ™è¿”å›æç¤ºä¿¡æ¯ï¼‰"""
    pass

def synthesize_summary(self, prompt: str) -> str:
    """ç”Ÿæˆæ–‡æœ¬æ‘˜è¦"""
    pass
```

### æ­¥éª¤4ï¼šæµ‹è¯•é›†æˆ

1. **è¿è¡Œæµ‹è¯•è„šæœ¬**ï¼š
   ```bash
   python test_custom_model.py
   ```

2. **æµ‹è¯•å®é™…ä½¿ç”¨**ï¼š
   ```bash
   python main.py your_input.mp4 output/ --huggingface-model your-org/your-model-name
   ```

## ğŸ“ æ¨¡å‹ç±»å‹ç¤ºä¾‹

### æ–‡æœ¬æ¨¡å‹ç¤ºä¾‹

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

class CustomTextModel:
    def __init__(self, model_id: str, verbose: bool = True):
        self.tokenizer = AutoTokenizer.from_pretrained(model_id)
        self.model = AutoModelForCausalLM.from_pretrained(
            model_id,
            torch_dtype=torch.float16,
            device_map="auto"
        )
    
    def _generate_text(self, prompt: str) -> str:
        inputs = self.tokenizer(prompt, return_tensors="pt")
        with torch.inference_mode():
            outputs = self.model.generate(**inputs, max_new_tokens=512)
        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)
```

### å›¾åƒæ¨¡å‹ç¤ºä¾‹

```python
from transformers import BlipProcessor, BlipForConditionalGeneration

class CustomImageModel:
    def __init__(self, model_id: str, verbose: bool = True):
        self.processor = BlipProcessor.from_pretrained(model_id)
        self.model = BlipForConditionalGeneration.from_pretrained(model_id)
    
    def describe_image(self, image_path: Path, prompt: str) -> str:
        image = Image.open(image_path)
        inputs = self.processor(image, prompt, return_tensors="pt")
        out = self.model.generate(**inputs, max_length=512)
        return self.processor.decode(out[0], skip_special_tokens=True)
```

## ğŸ”§ é«˜çº§é…ç½®

### è®¾å¤‡ç®¡ç†

```python
def _initialize_pipeline(self):
    # è‡ªåŠ¨æ£€æµ‹æœ€ä½³è®¾å¤‡
    self.device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # æ ¹æ®è®¾å¤‡è°ƒæ•´æ•°æ®ç±»å‹
    dtype = torch.float16 if torch.cuda.is_available() else torch.float32
    
    self.model = AutoModelForCausalLM.from_pretrained(
        self.model_id,
        torch_dtype=dtype,
        device_map="auto" if torch.cuda.is_available() else None
    )
```

### å†…å­˜ä¼˜åŒ–

```python
def _initialize_pipeline(self):
    # ä½¿ç”¨8bité‡åŒ–å‡å°‘å†…å­˜ä½¿ç”¨
    self.model = AutoModelForCausalLM.from_pretrained(
        self.model_id,
        load_in_8bit=True,  # 8bité‡åŒ–
        device_map="auto"
    )
```

### é”™è¯¯å¤„ç†

```python
def _generate_text(self, prompt: str) -> str:
    try:
        # ç”Ÿæˆé€»è¾‘
        return result
    except torch.cuda.OutOfMemoryError:
        console.log("[yellow]GPUå†…å­˜ä¸è¶³ï¼Œå°è¯•ä½¿ç”¨CPU...[/yellow]")
        # é™çº§åˆ°CPUå¤„ç†
        return self._generate_text_cpu(prompt)
    except Exception as e:
        console.log(f"[red]ç”Ÿæˆå¤±è´¥: {e}[/red]")
        return ""
```

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### å‘½ä»¤è¡Œä½¿ç”¨

```bash
# ä½¿ç”¨è‡ªå®šä¹‰æ–‡æœ¬æ¨¡å‹è¿›è¡Œæƒ…æ„Ÿåˆ†æ
python main.py video.mp4 output/ --huggingface-model meta-llama/Llama-2-7b-chat-hf

# ä½¿ç”¨è‡ªå®šä¹‰å›¾åƒæ¨¡å‹
python main.py image.jpg output/ --huggingface-model your-org/your-image-model
```

### ç¼–ç¨‹ä½¿ç”¨

```python
from mer_factory.models import LLMModels

# åˆå§‹åŒ–æ¨¡å‹
models = LLMModels(
    huggingface_model_id="your-org/your-model-name",
    verbose=True
)

# ä½¿ç”¨æ¨¡å‹
result = models.model_instance.describe_facial_expression("åˆ†æè¿™ä¸ªé¢éƒ¨è¡¨æƒ…")
print(result)
```

## ğŸ“š æ”¯æŒçš„æ¨¡å‹ç±»å‹

### æ–‡æœ¬ç”Ÿæˆæ¨¡å‹
- LLaMAç³»åˆ—ï¼š`meta-llama/Llama-2-7b-chat-hf`
- Mistralç³»åˆ—ï¼š`mistralai/Mistral-7B-Instruct-v0.2`
- DialoGPTï¼š`microsoft/DialoGPT-medium`
- GPT-2ï¼š`gpt2`

### å›¾åƒç†è§£æ¨¡å‹
- BLIPï¼š`Salesforce/blip-image-captioning-base`
- CLIPï¼š`openai/clip-vit-base-patch32`
- Vision Encoder-Decoderï¼š`nlpconnect/vit-gpt2-image-captioning`

### éŸ³é¢‘å¤„ç†æ¨¡å‹
- Whisperï¼š`openai/whisper-base`
- Wav2Vec2ï¼š`facebook/wav2vec2-base`

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **å†…å­˜è¦æ±‚**ï¼šå¤§å‹æ¨¡å‹éœ€è¦è¶³å¤Ÿçš„GPUå†…å­˜
2. **ä¾èµ–ç®¡ç†**ï¼šç¡®ä¿å®‰è£…æ¨¡å‹æ‰€éœ€çš„æ‰€æœ‰ä¾èµ–
3. **æ¨¡å‹å…¼å®¹æ€§**ï¼šæŸäº›æ¨¡å‹å¯èƒ½éœ€è¦ç‰¹å®šçš„transformersç‰ˆæœ¬
4. **æ€§èƒ½ä¼˜åŒ–**ï¼šè€ƒè™‘ä½¿ç”¨é‡åŒ–æˆ–æ¨¡å‹å¹¶è¡Œæ¥æé«˜æ•ˆç‡

## ğŸ†˜ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**ï¼š
   - ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹
   - å¯ç”¨8bitæˆ–4bité‡åŒ–
   - ä½¿ç”¨CPUæ¨ç†

2. **æ¨¡å‹åŠ è½½å¤±è´¥**ï¼š
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - éªŒè¯æ¨¡å‹IDæ˜¯å¦æ­£ç¡®
   - ç¡®è®¤transformersç‰ˆæœ¬å…¼å®¹æ€§

3. **ç”Ÿæˆè´¨é‡å·®**ï¼š
   - è°ƒæ•´ç”Ÿæˆå‚æ•°ï¼ˆtemperature, top_pç­‰ï¼‰
   - ä¼˜åŒ–æç¤ºè¯æ¨¡æ¿
   - å°è¯•ä¸åŒçš„æ¨¡å‹å˜ä½“

## ğŸ“ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œå¯ä»¥ï¼š
1. æŸ¥çœ‹é¡¹ç›®GitHub Issues
2. å‚è€ƒtransformerså®˜æ–¹æ–‡æ¡£
3. æ£€æŸ¥æ¨¡å‹åœ¨Hugging Face Hubä¸Šçš„è¯´æ˜

---

**ç¥ä½ åœ¨MER-Factoryä¸­æˆåŠŸé›†æˆæ–°çš„Hugging Faceæ¨¡å‹ï¼** ğŸ‰
